# Spam-Email-Detector-using-Naive-Bayes
Using training data and Naive Bayes (with Laplace Smoothing), found probabilities of certain words to be within spam email to detect the accuracy of testing data.

I started off by iterating through the ham and spam files of the training folder and concatenating each file to one another to create one giant text that I can tokenize in my “trainHam” and “trainSpam” methods. From these tokens, I created a dictionary of words as keys and kept track of the frequency of each word. Then, I looped through the ham and spam test files, and in each loop, I created a list of tokens for each file as well as how many times those words showed up in each file (so, a dictionary for each file). Then, using Laplace smoothing I calculated the probability of the key given it is a spam or ham file by adding 1 to the numerator and length of the keys to the denominator. To avoid underflow, I added up every log base 2 of each probability. If the probability of ham is greater than the probability of spam when testing the ham folder, then I increment 1 to the number of correctly classified files. Otherwise, we do not. I also kept a count of the total number of files. I then divided the total number of accurately classified files with the total number of files to find the accuracy percentage. I then repeated this with the spam testing folder except with this, if the probability of spam was greater than the probability of ham, I increment 2 to the number of correctly classified files. I then repeated this entire method with stop-words removed from the training data of ham and spam. 
Before removing stop-words, the accuracy of the testing data was about 90.52% for Ham, and 98.46% for Spam. After removing stop-words, the accuracy of the testing data dropped to 77.01% for Ham, however, Spam stayed the same at 98.46%. The reason why the accuracy dropped is because when stop-words are removed, the number of “y” values drops. In general, the more Y values you have, the more accurate your probability will be because with more data to base our training on, the more accurate we will be. This is especially true considering stop words occur very often in most texts. Therefore, removing them will remove a good chunk of keys from our training dictionaries.
